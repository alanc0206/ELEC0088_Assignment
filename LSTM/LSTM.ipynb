{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>21.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>21.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>21.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>22.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-07</th>\n",
       "      <td>187.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-08</th>\n",
       "      <td>182.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-09</th>\n",
       "      <td>172.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-10</th>\n",
       "      <td>173.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-13</th>\n",
       "      <td>165.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1307 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price\n",
       "Date              \n",
       "2018-01-02   21.37\n",
       "2018-01-03   21.15\n",
       "2018-01-04   20.97\n",
       "2018-01-05   21.11\n",
       "2018-01-08   22.43\n",
       "...            ...\n",
       "2023-03-07  187.71\n",
       "2023-03-08  182.00\n",
       "2023-03-09  172.92\n",
       "2023-03-10  173.44\n",
       "2023-03-13  165.87\n",
       "\n",
       "[1307 rows x 1 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "\n",
    "df = pd.read_csv('01_01_18_to_13_03_23.csv')\n",
    "df = df[['Date', 'Price']]\n",
    "df = df.set_index('Date', drop = True)\n",
    "df = df.iloc[::-1]\n",
    "df.index = pd.to_datetime(df.index, format=\"%d/%m/%Y\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-29</th>\n",
       "      <td>260.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>258.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-01</th>\n",
       "      <td>258.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-04</th>\n",
       "      <td>260.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-05</th>\n",
       "      <td>260.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-07</th>\n",
       "      <td>187.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-08</th>\n",
       "      <td>182.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-09</th>\n",
       "      <td>172.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-10</th>\n",
       "      <td>173.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-13</th>\n",
       "      <td>165.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price\n",
       "Date              \n",
       "2021-09-29  260.44\n",
       "2021-09-30  258.49\n",
       "2021-10-01  258.41\n",
       "2021-10-04  260.51\n",
       "2021-10-05  260.20\n",
       "...            ...\n",
       "2023-03-07  187.71\n",
       "2023-03-08  182.00\n",
       "2023-03-09  172.92\n",
       "2023-03-10  173.44\n",
       "2023-03-13  165.87\n",
       "\n",
       "[365 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference\n",
    "test_data = df.tail(365)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>21.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>21.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>21.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>22.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-22</th>\n",
       "      <td>250.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-23</th>\n",
       "      <td>251.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-24</th>\n",
       "      <td>258.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-27</th>\n",
       "      <td>263.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-28</th>\n",
       "      <td>259.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>942 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price\n",
       "Date              \n",
       "2018-01-02   21.37\n",
       "2018-01-03   21.15\n",
       "2018-01-04   20.97\n",
       "2018-01-05   21.11\n",
       "2018-01-08   22.43\n",
       "...            ...\n",
       "2021-09-22  250.65\n",
       "2021-09-23  251.21\n",
       "2021-09-24  258.13\n",
       "2021-09-27  263.79\n",
       "2021-09-28  259.19\n",
       "\n",
       "[942 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:-365]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2094365b5e0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 7))\n",
    "plt.plot(df.loc['2018-01-02':'2023-03-13','Price'],\n",
    "        label='Predicted', linestyle='-',  c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "\n",
    "# Prepare data for LSTM model by incoorporating timesteps of 60\n",
    "def prepare_data(data):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(60,len(data)):\n",
    "        x_train.append(data[i-60:i,0])\n",
    "        y_train.append(data[i,0])\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))\n",
    "    \n",
    "    return x_train, y_train\n",
    "\n",
    "# Build and train LSTM model\n",
    "def train_model(x_train,y_train):\n",
    "    model = Sequential()\n",
    "    n_neurons = x_train.shape[1] * x_train.shape[2]\n",
    "    model.add(LSTM(n_neurons,return_sequences=True,input_shape=(x_train.shape[1],x_train.shape[2])))\n",
    "    model.add(LSTM(n_neurons,return_sequences=False))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "    model.fit(x_train,y_train,epochs=500,batch_size=10,validation_split=0.2)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Make prediction\n",
    "def make_prediction(data,x_test_data):\n",
    "    x_train, y_train = prepare_data(data)\n",
    "    LSTM_model = train_model(x_train,y_train)\n",
    "    forecast = LSTM_model.predict(x_test_data)\n",
    "    #forecast = scaler.inverse_transform(forecast)\n",
    "    return forecast\n",
    "\n",
    "# Plot predictions and actual closing price \n",
    "def plot_predictions(total_data,test_data,forecast_data,title):\n",
    "    test_data['Prediction']= forecast_data\n",
    "    total_data.index = pd.to_datetime(total_data.index)\n",
    "    test_data.index = pd.to_datetime(test_data.index)\n",
    "    plt.figure(figsize=(16, 7))\n",
    "    plt.plot(total_data.loc['2021-09-29':'2023-03-13', 'Price'],\n",
    "             label='Actual', linestyle='-',  c='r')\n",
    "    plt.plot(test_data.loc['2021-09-29':'2023-03-13', 'Prediction'],\n",
    "             label='Predicted', linestyle='-',  c='b')\n",
    "    \n",
    "    plt.xlabel('Date',fontsize = '18')\n",
    "    plt.ylabel('Stock Price',fontsize = '18')\n",
    "    plt.title('Stock Prediction '+title,fontsize = '20')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.savefig('Stock Prediction '+title+'.png',\n",
    "                bbox_inches =\"tight\",\n",
    "                pad_inches = 0.5,\n",
    "                transparent = True,\n",
    "                facecolor =\"w\",\n",
    "                edgecolor ='w',\n",
    "                orientation ='landscape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "71/71 [==============================] - 5s 33ms/step - loss: 4743.7573 - val_loss: 45638.3125\n",
      "Epoch 2/500\n",
      "71/71 [==============================] - 2s 24ms/step - loss: 3685.7805 - val_loss: 39987.8750\n",
      "Epoch 3/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 3261.1748 - val_loss: 36175.6562\n",
      "Epoch 4/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 2759.0920 - val_loss: 31478.7520\n",
      "Epoch 5/500\n",
      "71/71 [==============================] - 2s 24ms/step - loss: 1963.2817 - val_loss: 25036.3848\n",
      "Epoch 6/500\n",
      "71/71 [==============================] - 2s 24ms/step - loss: 1344.1072 - val_loss: 19011.3398\n",
      "Epoch 7/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 901.1089 - val_loss: 14481.3203\n",
      "Epoch 8/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 633.0322 - val_loss: 11168.6387\n",
      "Epoch 9/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 483.0468 - val_loss: 9396.9639\n",
      "Epoch 10/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 423.0032 - val_loss: 7751.0269\n",
      "Epoch 11/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 316.2234 - val_loss: 5586.9463\n",
      "Epoch 12/500\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 276.1404 - val_loss: 5629.9888\n",
      "Epoch 13/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 265.9521 - val_loss: 4810.5757\n",
      "Epoch 14/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 283.8228 - val_loss: 5556.8931\n",
      "Epoch 15/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 291.4709 - val_loss: 5965.6553\n",
      "Epoch 16/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 274.3957 - val_loss: 5446.9375\n",
      "Epoch 17/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 220.6908 - val_loss: 3922.8853\n",
      "Epoch 18/500\n",
      "71/71 [==============================] - 2s 24ms/step - loss: 163.8161 - val_loss: 2804.4580\n",
      "Epoch 19/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 109.6677 - val_loss: 1668.9141\n",
      "Epoch 20/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 81.4497 - val_loss: 1258.1455\n",
      "Epoch 21/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 69.8686 - val_loss: 1028.9164\n",
      "Epoch 22/500\n",
      "71/71 [==============================] - 2s 24ms/step - loss: 57.1061 - val_loss: 836.3773\n",
      "Epoch 23/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 49.6440 - val_loss: 725.5113\n",
      "Epoch 24/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 48.1825 - val_loss: 651.6701\n",
      "Epoch 25/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 53.8479 - val_loss: 607.9429\n",
      "Epoch 26/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 47.1249 - val_loss: 670.4572\n",
      "Epoch 27/500\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 57.2718 - val_loss: 671.8974\n",
      "Epoch 28/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 46.7606 - val_loss: 722.0189\n",
      "Epoch 29/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 38.2265 - val_loss: 486.5976\n",
      "Epoch 30/500\n",
      "71/71 [==============================] - 2s 24ms/step - loss: 54.6867 - val_loss: 664.1852\n",
      "Epoch 31/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 47.4150 - val_loss: 662.3965\n",
      "Epoch 32/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 43.3001 - val_loss: 512.5002\n",
      "Epoch 33/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 35.8351 - val_loss: 600.8400\n",
      "Epoch 34/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 35.0131 - val_loss: 541.9328\n",
      "Epoch 35/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 38.7053 - val_loss: 769.5551\n",
      "Epoch 36/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 50.8594 - val_loss: 526.9301\n",
      "Epoch 37/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 30.2497 - val_loss: 504.3505\n",
      "Epoch 38/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 46.6486 - val_loss: 685.5380\n",
      "Epoch 39/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 30.1066 - val_loss: 649.0255\n",
      "Epoch 40/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 23.1288 - val_loss: 604.0980\n",
      "Epoch 41/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 28.3166 - val_loss: 217.7640\n",
      "Epoch 42/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 22.9908 - val_loss: 314.1487\n",
      "Epoch 43/500\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 27.8412 - val_loss: 1042.3120\n",
      "Epoch 44/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 22.2445 - val_loss: 366.0772\n",
      "Epoch 45/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 20.2379 - val_loss: 819.7328\n",
      "Epoch 46/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 21.5662 - val_loss: 488.0797\n",
      "Epoch 47/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 22.3066 - val_loss: 209.3526\n",
      "Epoch 48/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 37.8975 - val_loss: 538.0706\n",
      "Epoch 49/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 19.3935 - val_loss: 309.6288\n",
      "Epoch 50/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 14.9173 - val_loss: 244.1249\n",
      "Epoch 51/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 16.5857 - val_loss: 210.0626\n",
      "Epoch 52/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 15.3209 - val_loss: 153.9588\n",
      "Epoch 53/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 20.9883 - val_loss: 333.8759\n",
      "Epoch 54/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 17.4079 - val_loss: 604.0639\n",
      "Epoch 55/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 28.3272 - val_loss: 179.6167\n",
      "Epoch 56/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 15.6177 - val_loss: 751.7692\n",
      "Epoch 57/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 15.6139 - val_loss: 423.2112\n",
      "Epoch 58/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 16.5992 - val_loss: 727.4125\n",
      "Epoch 59/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 15.2700 - val_loss: 219.6396\n",
      "Epoch 60/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 11.9009 - val_loss: 123.6720\n",
      "Epoch 61/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 13.6485 - val_loss: 631.3298\n",
      "Epoch 62/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 40.2461 - val_loss: 363.2649\n",
      "Epoch 63/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 19.0843 - val_loss: 69.0145\n",
      "Epoch 64/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 17.2071 - val_loss: 253.4720\n",
      "Epoch 65/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 31.6498 - val_loss: 59.7916\n",
      "Epoch 66/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 24.4195 - val_loss: 336.2336\n",
      "Epoch 67/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 21.0632 - val_loss: 673.7650\n",
      "Epoch 68/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 18.7584 - val_loss: 108.6922\n",
      "Epoch 69/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 19.1868 - val_loss: 326.4837\n",
      "Epoch 70/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 17.6877 - val_loss: 127.2810\n",
      "Epoch 71/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 20.3395 - val_loss: 200.7790\n",
      "Epoch 72/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 16.9341 - val_loss: 159.7715\n",
      "Epoch 73/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 15.5388 - val_loss: 109.1089\n",
      "Epoch 74/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 19.9079 - val_loss: 158.9003\n",
      "Epoch 75/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 15.3545 - val_loss: 162.0511\n",
      "Epoch 76/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 19.6752 - val_loss: 143.9733\n",
      "Epoch 77/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 16.6370 - val_loss: 425.0698\n",
      "Epoch 78/500\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 14.9260 - val_loss: 548.6477\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 2s 30ms/step - loss: 19.8905 - val_loss: 146.5071\n",
      "Epoch 80/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 22.5103 - val_loss: 294.6705\n",
      "Epoch 81/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 19.0427 - val_loss: 95.8687\n",
      "Epoch 82/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 15.5734 - val_loss: 890.9092\n",
      "Epoch 83/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 26.2784 - val_loss: 89.4798\n",
      "Epoch 84/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 13.2972 - val_loss: 646.8080\n",
      "Epoch 85/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 13.9630 - val_loss: 160.3684\n",
      "Epoch 86/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 13.5304 - val_loss: 132.5084\n",
      "Epoch 87/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 20.7436 - val_loss: 397.4784\n",
      "Epoch 88/500\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 13.9315 - val_loss: 1978.9735\n",
      "Epoch 89/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 27.6282 - val_loss: 239.5111\n",
      "Epoch 90/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 14.8847 - val_loss: 954.8875\n",
      "Epoch 91/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 20.6766 - val_loss: 79.1071\n",
      "Epoch 92/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 20.6017 - val_loss: 97.4729\n",
      "Epoch 93/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 17.5453 - val_loss: 107.7317\n",
      "Epoch 94/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 13.4173 - val_loss: 221.9142\n",
      "Epoch 95/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 17.2837 - val_loss: 87.3311\n",
      "Epoch 96/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 13.4503 - val_loss: 184.5274\n",
      "Epoch 97/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 13.5652 - val_loss: 550.3295\n",
      "Epoch 98/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 14.3901 - val_loss: 103.4224\n",
      "Epoch 99/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 18.2256 - val_loss: 101.0168\n",
      "Epoch 100/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 29.8351 - val_loss: 436.7671\n",
      "Epoch 101/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 14.7431 - val_loss: 367.4213\n",
      "Epoch 102/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 15.3149 - val_loss: 123.3911\n",
      "Epoch 103/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 20.7919 - val_loss: 316.0319\n",
      "Epoch 104/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 14.9035 - val_loss: 182.2617\n",
      "Epoch 105/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 15.6778 - val_loss: 287.3457\n",
      "Epoch 106/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 13.3457 - val_loss: 549.7310\n",
      "Epoch 107/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 16.4589 - val_loss: 118.4295\n",
      "Epoch 108/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 12.7031 - val_loss: 421.0974\n",
      "Epoch 109/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 19.3319 - val_loss: 474.5027\n",
      "Epoch 110/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 23.9686 - val_loss: 516.6482\n",
      "Epoch 111/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 16.2733 - val_loss: 206.3388\n",
      "Epoch 112/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 15.3832 - val_loss: 153.4793\n",
      "Epoch 113/500\n",
      "71/71 [==============================] - 3s 40ms/step - loss: 16.3381 - val_loss: 151.5699\n",
      "Epoch 114/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 12.2510 - val_loss: 2209.4583\n",
      "Epoch 115/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 23.6068 - val_loss: 389.8144\n",
      "Epoch 116/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 13.9375 - val_loss: 140.4285\n",
      "Epoch 117/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 14.2344 - val_loss: 213.1568\n",
      "Epoch 118/500\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 15.1892 - val_loss: 171.1566\n",
      "Epoch 119/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 11.4527 - val_loss: 149.2600\n",
      "Epoch 120/500\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 15.1807 - val_loss: 316.7994\n",
      "Epoch 121/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 15.5300 - val_loss: 285.6125\n",
      "Epoch 122/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 11.7870 - val_loss: 186.9959\n",
      "Epoch 123/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 13.1131 - val_loss: 146.8080\n",
      "Epoch 124/500\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 18.8282 - val_loss: 119.0739\n",
      "Epoch 125/500\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 18.2394 - val_loss: 655.1115\n",
      "Epoch 126/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 16.7245 - val_loss: 154.6398\n",
      "Epoch 127/500\n",
      "71/71 [==============================] - 2s 25ms/step - loss: 13.7047 - val_loss: 166.5463\n",
      "Epoch 128/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 15.7101 - val_loss: 114.8188\n",
      "Epoch 129/500\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 17.5407 - val_loss: 772.1335\n",
      "Epoch 130/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 13.2747 - val_loss: 121.1276\n",
      "Epoch 131/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 15.1516 - val_loss: 134.8752\n",
      "Epoch 132/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 15.6513 - val_loss: 134.7593\n",
      "Epoch 133/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 16.9783 - val_loss: 199.6877\n",
      "Epoch 134/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 12.3735 - val_loss: 273.3607\n",
      "Epoch 135/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 12.8997 - val_loss: 716.4192\n",
      "Epoch 136/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 15.1164 - val_loss: 1641.7218\n",
      "Epoch 137/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 42.6233 - val_loss: 159.4193\n",
      "Epoch 138/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 16.3599 - val_loss: 253.4291\n",
      "Epoch 139/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 13.4361 - val_loss: 172.2225\n",
      "Epoch 140/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 14.3419 - val_loss: 138.7083\n",
      "Epoch 141/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 16.0702 - val_loss: 189.6457\n",
      "Epoch 142/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 15.2451 - val_loss: 339.6826\n",
      "Epoch 143/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 11.9504 - val_loss: 120.5263\n",
      "Epoch 144/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 18.9862 - val_loss: 155.3837\n",
      "Epoch 145/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 12.8061 - val_loss: 218.9852\n",
      "Epoch 146/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 13.0677 - val_loss: 109.9694\n",
      "Epoch 147/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 13.5709 - val_loss: 120.4294\n",
      "Epoch 148/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 15.7887 - val_loss: 229.8824\n",
      "Epoch 149/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 14.5634 - val_loss: 781.4800\n",
      "Epoch 150/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 13.9002 - val_loss: 115.5245\n",
      "Epoch 151/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 17.8264 - val_loss: 244.9666\n",
      "Epoch 152/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 14.2164 - val_loss: 111.7403\n",
      "Epoch 153/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 13.0553 - val_loss: 123.7046\n",
      "Epoch 154/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 17.2990 - val_loss: 116.9266\n",
      "Epoch 155/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 13.6387 - val_loss: 248.0283\n",
      "Epoch 156/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 18.3734 - val_loss: 74.6079\n",
      "Epoch 157/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 2s 27ms/step - loss: 15.2127 - val_loss: 278.7744\n",
      "Epoch 158/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 15.3005 - val_loss: 201.7086\n",
      "Epoch 159/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 13.6727 - val_loss: 218.7806\n",
      "Epoch 160/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 13.8109 - val_loss: 123.7663\n",
      "Epoch 161/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 11.8817 - val_loss: 441.3861\n",
      "Epoch 162/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 12.7686 - val_loss: 196.2412\n",
      "Epoch 163/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 21.8932 - val_loss: 137.5714\n",
      "Epoch 164/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 20.9527 - val_loss: 167.1400\n",
      "Epoch 165/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 16.5731 - val_loss: 255.8410\n",
      "Epoch 166/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 12.3221 - val_loss: 107.5789\n",
      "Epoch 167/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 11.9381 - val_loss: 127.8543\n",
      "Epoch 168/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 12.4669 - val_loss: 158.9259\n",
      "Epoch 169/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 15.3898 - val_loss: 670.9310\n",
      "Epoch 170/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 15.0595 - val_loss: 117.9157\n",
      "Epoch 171/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 17.2064 - val_loss: 196.0472\n",
      "Epoch 172/500\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 14.6180 - val_loss: 186.8075\n",
      "Epoch 173/500\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 12.8688 - val_loss: 123.0871\n",
      "Epoch 174/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 14.5585 - val_loss: 155.2737\n",
      "Epoch 175/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 13.1982 - val_loss: 112.0266\n",
      "Epoch 176/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 12.7219 - val_loss: 155.8013\n",
      "Epoch 177/500\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 10.8458 - val_loss: 93.6249\n",
      "Epoch 178/500\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 13.3866 - val_loss: 273.9309\n",
      "Epoch 179/500\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 17.4016 - val_loss: 283.0853\n",
      "Epoch 180/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 11.1068 - val_loss: 107.1061\n",
      "Epoch 181/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 12.2913 - val_loss: 445.4412\n",
      "Epoch 182/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 15.3600 - val_loss: 99.4794\n",
      "Epoch 183/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 14.9093 - val_loss: 201.2599\n",
      "Epoch 184/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 14.1420 - val_loss: 99.0774\n",
      "Epoch 185/500\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 15.0866 - val_loss: 260.1353\n",
      "Epoch 186/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 12.4220 - val_loss: 657.8016\n",
      "Epoch 187/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 14.6692 - val_loss: 979.5154\n",
      "Epoch 188/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 25.0933 - val_loss: 81.8718\n",
      "Epoch 189/500\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 14.4956 - val_loss: 92.8228\n",
      "Epoch 190/500\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 12.0338 - val_loss: 102.2079\n",
      "Epoch 191/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 11.3394 - val_loss: 277.0717\n",
      "Epoch 192/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 13.1147 - val_loss: 322.8300\n",
      "Epoch 193/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 12.4708 - val_loss: 92.7389\n",
      "Epoch 194/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 15.3556 - val_loss: 2555.7346\n",
      "Epoch 195/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 37.0704 - val_loss: 150.1936\n",
      "Epoch 196/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 12.1346 - val_loss: 95.7468\n",
      "Epoch 197/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 12.9136 - val_loss: 105.9071\n",
      "Epoch 198/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 11.0932 - val_loss: 1069.6125\n",
      "Epoch 199/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 12.9448 - val_loss: 289.9027\n",
      "Epoch 200/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 11.8153 - val_loss: 189.7950\n",
      "Epoch 201/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 15.9686 - val_loss: 94.6244\n",
      "Epoch 202/500\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 11.8060 - val_loss: 614.0977\n",
      "Epoch 203/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 17.9856 - val_loss: 88.6271\n",
      "Epoch 204/500\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 13.9208 - val_loss: 109.4969\n",
      "Epoch 205/500\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 11.7932 - val_loss: 94.9156\n",
      "Epoch 206/500\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 13.6768 - val_loss: 838.6359\n",
      "Epoch 207/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 15.7285 - val_loss: 90.1503\n",
      "Epoch 208/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 11.2203 - val_loss: 335.7005\n",
      "Epoch 209/500\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 15.5917 - val_loss: 273.7806\n",
      "Epoch 210/500\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 13.1626 - val_loss: 133.1447\n",
      "Epoch 211/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 12.7865 - val_loss: 85.1931\n",
      "Epoch 212/500\n",
      "71/71 [==============================] - 3s 40ms/step - loss: 14.5007 - val_loss: 99.3862\n",
      "Epoch 213/500\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 11.4659 - val_loss: 141.3795\n",
      "Epoch 214/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 10.9846 - val_loss: 411.0082\n",
      "Epoch 215/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 12.5622 - val_loss: 191.9860\n",
      "Epoch 216/500\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 11.7565 - val_loss: 95.3225\n",
      "Epoch 217/500\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 14.2127 - val_loss: 91.0461\n",
      "Epoch 218/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 11.0793 - val_loss: 177.5822\n",
      "Epoch 219/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 14.6551 - val_loss: 122.0665\n",
      "Epoch 220/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 10.5357 - val_loss: 145.7033\n",
      "Epoch 221/500\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 10.9636 - val_loss: 122.7646\n",
      "Epoch 222/500\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 11.2714 - val_loss: 173.5887\n",
      "Epoch 223/500\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 13.9802 - val_loss: 106.2949\n",
      "Epoch 224/500\n",
      "71/71 [==============================] - 3s 46ms/step - loss: 11.6962 - val_loss: 1241.6670\n",
      "Epoch 225/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 15.2004 - val_loss: 189.0639\n",
      "Epoch 226/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 11.4572 - val_loss: 225.0196\n",
      "Epoch 227/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 18.0100 - val_loss: 980.7383\n",
      "Epoch 228/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 17.5581 - val_loss: 94.7274\n",
      "Epoch 229/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 14.3410 - val_loss: 141.5326\n",
      "Epoch 230/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 12.5568 - val_loss: 297.9341\n",
      "Epoch 231/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 14.0929 - val_loss: 302.2257\n",
      "Epoch 232/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 12.4331 - val_loss: 198.6442\n",
      "Epoch 233/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 14.6823 - val_loss: 233.9049\n",
      "Epoch 234/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 13.1565 - val_loss: 1040.3788\n",
      "Epoch 235/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 2s 27ms/step - loss: 15.3827 - val_loss: 172.8776\n",
      "Epoch 236/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 19.1774 - val_loss: 584.4877\n",
      "Epoch 237/500\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 21.2937 - val_loss: 188.7737\n",
      "Epoch 238/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 11.7599 - val_loss: 215.8613\n",
      "Epoch 239/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 11.4984 - val_loss: 192.1855\n",
      "Epoch 240/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 12.6757 - val_loss: 143.0276\n",
      "Epoch 241/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 12.1828 - val_loss: 146.9221\n",
      "Epoch 242/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 12.6120 - val_loss: 105.7410\n",
      "Epoch 243/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 13.7110 - val_loss: 141.3537\n",
      "Epoch 244/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 11.8224 - val_loss: 171.1631\n",
      "Epoch 245/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 11.3148 - val_loss: 86.9751\n",
      "Epoch 246/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 10.9711 - val_loss: 144.2200\n",
      "Epoch 247/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 12.9683 - val_loss: 88.9044\n",
      "Epoch 248/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 10.7406 - val_loss: 121.6633\n",
      "Epoch 249/500\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 11.7657 - val_loss: 203.4868\n",
      "Epoch 250/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 10.0175 - val_loss: 121.1048\n",
      "Epoch 251/500\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 11.0190 - val_loss: 93.9387\n",
      "Epoch 252/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 12.2188 - val_loss: 229.2588\n",
      "Epoch 253/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 11.4259 - val_loss: 149.5133\n",
      "Epoch 254/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 10.6684 - val_loss: 88.6601\n",
      "Epoch 255/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 14.1716 - val_loss: 98.0207\n",
      "Epoch 256/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 13.9742 - val_loss: 129.3343\n",
      "Epoch 257/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 19.2944 - val_loss: 115.6879\n",
      "Epoch 258/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 14.5508 - val_loss: 403.5310\n",
      "Epoch 259/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 14.5139 - val_loss: 255.8051\n",
      "Epoch 260/500\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 11.7095 - val_loss: 195.3904\n",
      "Epoch 261/500\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 12.0633 - val_loss: 105.7173\n",
      "Epoch 262/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 11.0341 - val_loss: 225.2491\n",
      "Epoch 263/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 12.3117 - val_loss: 97.3345\n",
      "Epoch 264/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 11.5697 - val_loss: 151.5378\n",
      "Epoch 265/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 13.6359 - val_loss: 114.7473\n",
      "Epoch 266/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 12.6476 - val_loss: 142.2855\n",
      "Epoch 267/500\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 11.0183 - val_loss: 165.1873\n",
      "Epoch 268/500\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 12.2548 - val_loss: 151.4338\n",
      "Epoch 269/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 11.4532 - val_loss: 507.1137\n",
      "Epoch 270/500\n",
      "71/71 [==============================] - 3s 40ms/step - loss: 13.3175 - val_loss: 110.5065\n",
      "Epoch 271/500\n",
      "71/71 [==============================] - 3s 47ms/step - loss: 11.6358 - val_loss: 109.4155\n",
      "Epoch 272/500\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 13.1783 - val_loss: 319.0827\n",
      "Epoch 273/500\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 11.5168 - val_loss: 172.0162\n",
      "Epoch 274/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 13.8329 - val_loss: 125.1608\n",
      "Epoch 275/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 13.9420 - val_loss: 496.7339\n",
      "Epoch 276/500\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 14.7230 - val_loss: 372.6974\n",
      "Epoch 277/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 13.2912 - val_loss: 105.7404\n",
      "Epoch 278/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 9.9539 - val_loss: 301.6479\n",
      "Epoch 279/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 10.5972 - val_loss: 218.3143\n",
      "Epoch 280/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 13.0115 - val_loss: 167.0324\n",
      "Epoch 281/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 12.0864 - val_loss: 184.7604\n",
      "Epoch 282/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 10.3922 - val_loss: 309.1883\n",
      "Epoch 283/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 10.9933 - val_loss: 209.9214\n",
      "Epoch 284/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 10.0230 - val_loss: 154.1560\n",
      "Epoch 285/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 12.1076 - val_loss: 130.3571\n",
      "Epoch 286/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 12.2760 - val_loss: 544.2971\n",
      "Epoch 287/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 15.9957 - val_loss: 540.3300\n",
      "Epoch 288/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 11.9774 - val_loss: 863.3359\n",
      "Epoch 289/500\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 14.0034 - val_loss: 305.4536\n",
      "Epoch 290/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 11.0110 - val_loss: 282.6617\n",
      "Epoch 291/500\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 11.9457 - val_loss: 99.4483\n",
      "Epoch 292/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 11.6186 - val_loss: 244.8077\n",
      "Epoch 293/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 9.9979 - val_loss: 498.2375\n",
      "Epoch 294/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 9.6163 - val_loss: 200.3233\n",
      "Epoch 295/500\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 10.7948 - val_loss: 130.3448\n",
      "Epoch 296/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 11.1708 - val_loss: 469.7756\n",
      "Epoch 297/500\n",
      "71/71 [==============================] - 3s 47ms/step - loss: 12.3194 - val_loss: 236.7449\n",
      "Epoch 298/500\n",
      "71/71 [==============================] - 3s 40ms/step - loss: 9.8022 - val_loss: 117.6123\n",
      "Epoch 299/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 21.0634 - val_loss: 633.3348\n",
      "Epoch 300/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 14.0271 - val_loss: 404.7983\n",
      "Epoch 301/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 22.6251 - val_loss: 794.3398\n",
      "Epoch 302/500\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 16.2519 - val_loss: 218.6756\n",
      "Epoch 303/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 11.1892 - val_loss: 239.8508\n",
      "Epoch 304/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 10.5473 - val_loss: 203.4740\n",
      "Epoch 305/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 10.9930 - val_loss: 192.5134\n",
      "Epoch 306/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 10.1164 - val_loss: 290.2750\n",
      "Epoch 307/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 9.9170 - val_loss: 137.1588\n",
      "Epoch 308/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 12.6118 - val_loss: 135.3156\n",
      "Epoch 309/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 13.6162 - val_loss: 166.9875\n",
      "Epoch 310/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 18.4384 - val_loss: 247.2537\n",
      "Epoch 311/500\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 11.2164 - val_loss: 625.7231\n",
      "Epoch 312/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 10.9617 - val_loss: 167.5023\n",
      "Epoch 313/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 3s 36ms/step - loss: 10.8229 - val_loss: 141.0703\n",
      "Epoch 314/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 11.0228 - val_loss: 453.2163\n",
      "Epoch 315/500\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 13.6852 - val_loss: 189.5922\n",
      "Epoch 316/500\n",
      "71/71 [==============================] - 2s 35ms/step - loss: 10.7022 - val_loss: 178.2518\n",
      "Epoch 317/500\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 9.1383 - val_loss: 284.3511\n",
      "Epoch 318/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 10.9831 - val_loss: 198.4656\n",
      "Epoch 319/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 12.4546 - val_loss: 290.3827\n",
      "Epoch 320/500\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 15.3982 - val_loss: 294.4445\n",
      "Epoch 321/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 11.9851 - val_loss: 638.8043\n",
      "Epoch 322/500\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 11.7724 - val_loss: 433.0078\n",
      "Epoch 323/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 11.3319 - val_loss: 246.3931\n",
      "Epoch 324/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 16.0691 - val_loss: 348.0054\n",
      "Epoch 325/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 14.9873 - val_loss: 350.2137\n",
      "Epoch 326/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 13.5726 - val_loss: 106.3399\n",
      "Epoch 327/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 18.1289 - val_loss: 171.2469\n",
      "Epoch 328/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 14.7261 - val_loss: 119.8016\n",
      "Epoch 329/500\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 11.5245 - val_loss: 214.1493\n",
      "Epoch 330/500\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 10.7570 - val_loss: 138.4160\n",
      "Epoch 331/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 14.7677 - val_loss: 203.9845\n",
      "Epoch 332/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 9.9858 - val_loss: 207.4224\n",
      "Epoch 333/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 10.4188 - val_loss: 131.3232\n",
      "Epoch 334/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 11.2126 - val_loss: 135.0664\n",
      "Epoch 335/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 10.2365 - val_loss: 106.9878\n",
      "Epoch 336/500\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 11.8768 - val_loss: 95.1543\n",
      "Epoch 337/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 12.0649 - val_loss: 484.8701\n",
      "Epoch 338/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 12.6069 - val_loss: 388.3355\n",
      "Epoch 339/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 10.6417 - val_loss: 603.1767\n",
      "Epoch 340/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 10.0240 - val_loss: 303.9614\n",
      "Epoch 341/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 9.7974 - val_loss: 239.1368\n",
      "Epoch 342/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 9.9192 - val_loss: 298.8250\n",
      "Epoch 343/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 9.3858 - val_loss: 116.4814\n",
      "Epoch 344/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 12.6009 - val_loss: 849.3508\n",
      "Epoch 345/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 10.8403 - val_loss: 122.0272\n",
      "Epoch 346/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 9.1871 - val_loss: 396.5585\n",
      "Epoch 347/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 10.2966 - val_loss: 225.9426\n",
      "Epoch 348/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 10.7976 - val_loss: 203.5906\n",
      "Epoch 349/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 12.3392 - val_loss: 280.4738\n",
      "Epoch 350/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 10.4203 - val_loss: 97.2104\n",
      "Epoch 351/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 10.8276 - val_loss: 133.9903\n",
      "Epoch 352/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 9.0928 - val_loss: 111.4401\n",
      "Epoch 353/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 10.4602 - val_loss: 113.6051\n",
      "Epoch 354/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 12.3099 - val_loss: 124.5987\n",
      "Epoch 355/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 11.9728 - val_loss: 426.5816\n",
      "Epoch 356/500\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 23.6220 - val_loss: 224.9945\n",
      "Epoch 357/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 15.9773 - val_loss: 829.4470\n",
      "Epoch 358/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 10.5492 - val_loss: 614.4992\n",
      "Epoch 359/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 14.7163 - val_loss: 991.4763\n",
      "Epoch 360/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 11.2096 - val_loss: 273.1142\n",
      "Epoch 361/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 10.5151 - val_loss: 260.9807\n",
      "Epoch 362/500\n",
      "71/71 [==============================] - 2s 26ms/step - loss: 11.1547 - val_loss: 150.3049\n",
      "Epoch 363/500\n",
      "71/71 [==============================] - 2s 27ms/step - loss: 12.0833 - val_loss: 423.5401\n",
      "Epoch 364/500\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 9.5424 - val_loss: 458.6672\n",
      "Epoch 365/500\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 12.4247 - val_loss: 442.1830\n",
      "Epoch 366/500\n",
      "71/71 [==============================] - 2s 28ms/step - loss: 12.2780 - val_loss: 165.0166\n",
      "Epoch 367/500\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 11.8777 - val_loss: 153.1441\n",
      "Epoch 368/500\n",
      "71/71 [==============================] - 3s 35ms/step - loss: 9.8964 - val_loss: 156.4760\n",
      "Epoch 369/500\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 10.4185 - val_loss: 189.0331\n",
      "Epoch 370/500\n",
      "71/71 [==============================] - 3s 43ms/step - loss: 10.6706 - val_loss: 287.5330\n",
      "Epoch 371/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 9.2580 - val_loss: 149.6140\n",
      "Epoch 372/500\n",
      "71/71 [==============================] - 2s 34ms/step - loss: 9.5419 - val_loss: 461.9178\n",
      "Epoch 373/500\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 11.0445 - val_loss: 134.9859\n",
      "Epoch 374/500\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 9.7629 - val_loss: 401.5867\n",
      "Epoch 375/500\n",
      "71/71 [==============================] - 2s 29ms/step - loss: 9.8823 - val_loss: 153.9482\n",
      "Epoch 376/500\n",
      "71/71 [==============================] - 2s 30ms/step - loss: 10.4897 - val_loss: 255.6181\n",
      "Epoch 377/500\n",
      "31/71 [============>.................] - ETA: 1s - loss: 10.3574"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Prepare test data\n",
    "hist_data = pd.DataFrame(df['Price'])\n",
    "#hist_data.index = hist_data.index.strftime('%Y-%m-%d')\n",
    "dataset_total = pd.concat((hist_data, test_data), axis = 0)\n",
    "inputs = dataset_total.iloc[len(dataset_total) - len(test_data) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "#inputs = scaler.fit_transform(inputs)\n",
    "x_test, y_test = prepare_data(inputs)\n",
    "\n",
    "# LSTM Model \n",
    "train = df.values\n",
    "forecast = make_prediction(train,x_test)\n",
    "plot_predictions(dataset_total,test_data,forecast,'Prediction')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Root Mean Squared Error between actual and  predicted values: \",rmse(test_data['Prediction'],test_data['Price']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
